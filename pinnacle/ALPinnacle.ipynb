{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce80ba17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7e922c3d1ab0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from typing import Dict, Any, Tuple, Union, NamedTuple\n",
    "import hydra\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lr = 1e-3\n",
    "lbd_lr = 1e-2\n",
    "max_steps = 20000\n",
    "print_freq = 100\n",
    "\n",
    "#8 layers, 256 neurons test.\n",
    "\n",
    "torch.manual_seed(995) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8377fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lc = 1e-9\n",
    "cc = 1e-5\n",
    "# Physical constants\n",
    "F = 96485 # Faraday constant [C/mol]\n",
    "R = 8.3145 # Gas constant [J/(mol·K)]\n",
    "T = 293 # Temperature [K]\n",
    "k_B = 1.3806e-23 # Boltzmann constant [J/K]\n",
    "eps0 = 8.85e-12 # Vacuum permittivity [F/m]\n",
    "E_min = -1.0  # External applied potential [V] \n",
    "E_max = 1.8\n",
    "# Diffusion coefficients [m²/s]\n",
    "D_cv = 1.0e-21\n",
    "D_av = 1.0e-21\n",
    "D_h = 3.2823e-4\n",
    "\n",
    "# Mobility coefficients [m²/(V·s)]\n",
    "U_cv = -1.0562e-19\n",
    "U_av = 7.9212e-20\n",
    "U_h = 0.013 # mo_h from COMSOL\n",
    "\n",
    "# Species charges\n",
    "z_cv = -2.6667 # -8/3\n",
    "z_av = 2\n",
    "z_h = 1\n",
    "\n",
    "# Permittivities [F/m]\n",
    "epsilonf = 1.239e-10 # 14*eps0\n",
    "eps_film = 1.239e-10 # Same as epsilonf\n",
    "eps_Ddl = 1.77e-11 # 2*eps0\n",
    "eps_dl = 6.947e-10 # 78.5*eps0\n",
    "eps_sol = 6.947e-10 # Same as eps_dl\n",
    "\n",
    "# Semiconductor properties\n",
    "c_h0 = 4.1683e-4 # Intrinsic hole concentration [mol/m³]\n",
    "c_e0 = 9.5329e-28 # Intrinsic electron concentration [mol/m³]\n",
    "tau = 4.9817e-13 # Recombination time constant [s·mol/m³]\n",
    "Nc = 166.06 # Conduction band density [mol/m³]\n",
    "Nv = 1.6606e5 # Valence band density [mol/m³]\n",
    "mu_e0 = 2.4033e-19 # Standard electron chemical potential [J]\n",
    "Ec0 = 5.127e-19 # Conduction band edge [J]\n",
    "Ev0 = 1.6022e-19 # Valence band edge [J]\n",
    "\n",
    "# Solution properties\n",
    "c_H = 0.01 # Proton concentration [mol/m³]\n",
    "pH = 5\n",
    "\n",
    "# Molar volume\n",
    "Omega = 1.4e-5 # [m³/mol]\n",
    "# Standard rate constants\n",
    "k1_0 = 4.5e-8 # [m/s]\n",
    "k2_0 = 3.6e-6 # [mol/(m²·s)]\n",
    "k3_0 = 4.5e-9 # [mol/(m²·s)]\n",
    "k4_0 = 2.25e-7 # [m/s]\n",
    "k5_0 = 7.65e-9 # [mol/(m²·s)]\n",
    "ktp_0 = 4.5e-8 # [-]\n",
    "ko2_0 = 0.005 # [m/s]\n",
    "\n",
    "# Charge transfer coefficients\n",
    "alpha_cv = 0.3\n",
    "alpha_av = 0.8\n",
    "beta_cv = 0.1\n",
    "beta_av = 0.8\n",
    "alpha_tp = 0.2\n",
    "a_par = 0.45 # For oxygen evolution\n",
    "delta3 = 1.0\n",
    "\n",
    "# Derived parameters [1/V]\n",
    "a_cv = 23.764 # alpha_cv * 2 * F/(R*T)\n",
    "a_av = 84.493 # alpha_av * 8/3 * F/(R*T)\n",
    "b_cv = 7.9212 # beta_cv * 2 * F/(R*T)\n",
    "\n",
    "# Geometric parameters [m]\n",
    "d_Ddl = 2.0e-10 # Defect layer thickness\n",
    "d_dl = 5.0e-10 # Double layer thickness\n",
    "L_cell = 1.0e-6 # Cell length\n",
    "\n",
    "# Equilibrium potentials\n",
    "phi_O2_eq = 1.35 # [V]\n",
    "phic = (R*T)/F\n",
    "tc = (lc ** 2) / D_cv\n",
    "L_initial = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1c9a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define networks\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return torch.sigmoid(x)*x\n",
    "    \n",
    "\n",
    "class FFN(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully Connected Feed Forward Neural Network.\n",
    "    Args:\n",
    "        input_dim: Number of input features\n",
    "        output_dim: Number of output features  \n",
    "        hidden_layers: Number of hidden layers\n",
    "        layer_size: Size of each hidden layer\n",
    "        activation: Activation function name ('swish', 'swoosh', 'swash', 'squash_swish', 'relu', 'tanh')\n",
    "        initialize_weights: Whether to apply Xavier initialization\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 3,\n",
    "        output_dim: int = 1,\n",
    "        hidden_layers: int = 8,\n",
    "        layer_size: int = 256,\n",
    "        activation: str = \"swish\",\n",
    "        initialize_weights: bool = False\n",
    "    ):\n",
    "        super(FFN, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = hidden_layers\n",
    "        self.layer_size = layer_size\n",
    "        self.activation = Swish()\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_dim, self.layer_size)\n",
    "        \n",
    "        # Hidden layers\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(self.layer_size, self.layer_size)\n",
    "            for _ in range(self.num_layers)  \n",
    "        ])\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(self.layer_size, output_dim)\n",
    "        \n",
    "        # Initialize weights\n",
    "        if initialize_weights:\n",
    "            self.initialize_weights()\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        \"\"\"Apply Xavier initialization to all linear layers\"\"\"\n",
    "        # Initialize input layer\n",
    "        nn.init.xavier_normal_(self.input_layer.weight)\n",
    "        nn.init.zeros_(self.input_layer.bias)\n",
    "        \n",
    "        # Initialize hidden layers\n",
    "        for layer in self.hidden_layers:\n",
    "            nn.init.xavier_normal_(layer.weight)\n",
    "            nn.init.zeros_(layer.bias)\n",
    "        \n",
    "        # Initialize output layer\n",
    "        nn.init.xavier_normal_(self.output_layer.weight)\n",
    "        nn.init.zeros_(self.output_layer.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.input_layer(x))\n",
    "        \n",
    "        for layer in self.hidden_layers: \n",
    "            x = self.activation(layer(x))\n",
    "        \n",
    "        return self.output_layer(x)\n",
    "\n",
    "\n",
    "cv_net = FFN()\n",
    "av_net = FFN()\n",
    "u_net = FFN()\n",
    "L_net = FFN(2,1)\n",
    "cv_net.to(device)\n",
    "av_net.to(device)\n",
    "u_net.to(device)\n",
    "L_net.to(device)\n",
    "\n",
    "total_model_parameters = list(cv_net.parameters()) + list(av_net.parameters()) + list(u_net.parameters()) + list(L_net.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5c53c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient and sampling utils\n",
    "\n",
    "class GradientResults(NamedTuple):\n",
    "    \"\"\"\n",
    "    Container for gradient computation results.\n",
    "\n",
    "    Organizes all computed derivatives in a structured way for easy access.\n",
    "    \"\"\"\n",
    "    # Network predictions\n",
    "    phi: torch.Tensor  # Potential φ\n",
    "    c_cv: torch.Tensor  # Cation vacancy concentration\n",
    "    c_av: torch.Tensor  # Anion vacancy concentration\n",
    "\n",
    "    # Time derivatives\n",
    "    c_cv_t: torch.Tensor  # ∂c_cv/∂t\n",
    "    c_av_t: torch.Tensor  # ∂c_av/∂t\n",
    "\n",
    "    # First spatial derivatives\n",
    "    phi_x: torch.Tensor  # ∂φ/∂x\n",
    "    c_cv_x: torch.Tensor  # ∂c_cv/∂x\n",
    "    c_av_x: torch.Tensor  # ∂c_av/∂x\n",
    "\n",
    "    # Second spatial derivatives\n",
    "    phi_xx: torch.Tensor  # ∂²φ/∂x²\n",
    "    c_cv_xx: torch.Tensor  # ∂²c_cv/∂x²\n",
    "    c_av_xx: torch.Tensor  # ∂²c_av/∂x²\n",
    "\n",
    "\n",
    "def _grad(x,dx):\n",
    "    \"\"\"Take the derrivative of x w.r.t dx\"\"\"\n",
    "\n",
    "    return torch.autograd.grad(x,dx,torch.ones_like(dx),create_graph=True,retain_graph=True)[0]\n",
    "\n",
    "def compute_gradients(x, t, E):\n",
    "    inputs_3d = torch.cat([x, t, E], dim=1)\n",
    "\n",
    "    # Get network predictions\n",
    "    phi = u_net(inputs_3d)\n",
    "    c_cv_raw = cv_net(inputs_3d)\n",
    "    c_av_raw = av_net(inputs_3d)\n",
    "\n",
    "\n",
    "    # Networks predict concentrations directly\n",
    "    c_cv = c_cv_raw\n",
    "    c_av = c_av_raw\n",
    "\n",
    "\n",
    "    # Direct derivatives\n",
    "    c_cv_t = _grad(c_cv, t)\n",
    "    c_av_t = _grad(c_av, t)\n",
    "\n",
    "    # Compute first spatial derivatives\n",
    "    phi_x = _grad(phi, x)\n",
    "\n",
    "    c_cv_x = _grad(c_cv, x)\n",
    "    c_av_x = _grad(c_av, x)\n",
    "\n",
    "    # Compute second spatial derivatives\n",
    "    phi_xx = _grad(phi_x, x)\n",
    "\n",
    "    c_cv_xx = _grad(c_cv_x, x)\n",
    "    c_av_xx = _grad(c_av_x, x)\n",
    "\n",
    "    return GradientResults(\n",
    "        phi=phi, c_cv=c_cv, c_av=c_av,\n",
    "        c_cv_t=c_cv_t, c_av_t=c_av_t,\n",
    "        phi_x=phi_x, c_cv_x=c_cv_x, c_av_x=c_av_x, \n",
    "        phi_xx=phi_xx, c_cv_xx=c_cv_xx, c_av_xx=c_av_xx\n",
    "    )\n",
    "\n",
    "def sample_interior_points(\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Sample interior collocation points for PDE residuals.\n",
    "\n",
    "        Args:\n",
    "            networks: NetworkManager instance\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (x, t, E) tensors with requires_grad=True for x and t\n",
    "        \"\"\"\n",
    "        batch_size = 2048\n",
    "\n",
    "        # Sample time and applied potential\n",
    "        t = torch.rand(batch_size, 1, device=device, requires_grad=True)\n",
    "        single_E = torch.tensor(0.8,device=device)\n",
    "        E = single_E.expand(batch_size, 1)\n",
    "\n",
    "        # Get film thickness prediction\n",
    "        L_pred = L_net(torch.cat([t, E], dim=1))\n",
    "\n",
    "        # Sample spatial coordinates within [0, L(t,E)]\n",
    "        x = torch.rand(batch_size, 1, device=device, requires_grad=True) * L_pred\n",
    "\n",
    "        return x, t, E\n",
    "\n",
    "def sample_boundary_points(\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Sample boundary collocation points for boundary conditions.\n",
    "\n",
    "    Args:\n",
    "        networks: NetworkManager instance\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (x, t, E) tensors for boundary points\n",
    "    \"\"\"\n",
    "    batch_size = 2 * 1024\n",
    "\n",
    "    # Sample time and applied potential\n",
    "    t = torch.rand(batch_size, 1, device=device, requires_grad=True)\n",
    "    single_E = torch.tensor(0.8,device=device)\n",
    "    E = single_E.expand(batch_size, 1)\n",
    "\n",
    "    # Predict L for f/s boundary\n",
    "    L_inputs = torch.cat([t, E], dim=1)\n",
    "    L_pred = L_net(L_inputs)\n",
    "\n",
    "    half_batch = batch_size // 2\n",
    "\n",
    "    # Metal/film interface points (x = 0)\n",
    "    x_mf = torch.zeros(half_batch, 1, device=device, requires_grad=True)\n",
    "    t_mf = t[:half_batch]\n",
    "    E_mf = E[:half_batch]\n",
    "\n",
    "    # Film/solution interface points (x = L)\n",
    "    x_fs = L_pred[half_batch:]\n",
    "    t_fs = t[half_batch:]\n",
    "    E_fs = E[half_batch:]\n",
    "\n",
    "    # Combine boundary points\n",
    "    x_boundary = torch.cat([x_mf, x_fs], dim=0)\n",
    "    t_boundary = torch.cat([t_mf, t_fs], dim=0)\n",
    "    E_boundary = torch.cat([E_mf, E_fs], dim=0)\n",
    "\n",
    "    return x_boundary, t_boundary, E_boundary\n",
    "\n",
    "def sample_initial_points(\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Sample initial condition points at t = 0.\n",
    "\n",
    "    Args:\n",
    "        networks: NetworkManager instance\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (x, t, E) tensors for initial condition points\n",
    "    \"\"\"\n",
    "    batch_size = 1024\n",
    "\n",
    "    # Initial time (t = 0)\n",
    "    t = torch.zeros(batch_size, 1, device=device, requires_grad=True)\n",
    "    single_E = torch.tensor(0.8,device=device)\n",
    "    E = single_E.expand(batch_size, 1)\n",
    "\n",
    "    # Get initial film thickness\n",
    "    L_initial_pred = L_net(torch.cat([t, E], dim=1))\n",
    "\n",
    "    # Sample spatial coordinates\n",
    "    x = (\n",
    "        torch.rand(batch_size, 1, device=device, requires_grad=True)\n",
    "        * L_initial_pred\n",
    "    )\n",
    "\n",
    "    return x, t, E\n",
    "\n",
    "def sample_film_physics_points() -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Sample points for film growth physics constraint.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (t, E) tensors for film physics constraint\n",
    "    \"\"\"\n",
    "    batch_size = 2048\n",
    "\n",
    "    # Sample time and applied potential\n",
    "    t = torch.rand(batch_size, 1, device=device, requires_grad=True)\n",
    "    single_E = torch.tensor(0.8,device=device)\n",
    "    E = single_E.expand(batch_size, 1)\n",
    "\n",
    "    return t, E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75116210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and generate all the relevant losses\n",
    "\n",
    "def compute_rate_constants(t: torch.Tensor, E: torch.Tensor, single: bool = False):\n",
    "        \"\"\"\n",
    "        Compute electrochemical rate constants using Butler-Volmer kinetics.\n",
    "\n",
    "        **Butler-Volmer Rate Expressions:**\n",
    "\n",
    "        .. math::\n",
    "            \\\\hat{k}_{R1} = k_1^0 \\\\exp\\\\left(\\\\alpha_1 \\\\frac{3F\\\\hat{\\\\phi}_c}{RT}\\\\hat{\\\\phi}_{mf} \\\\right)\n",
    "\n",
    "        .. math::\n",
    "            \\\\hat{k}_{R2} = k_2^0 \\\\exp\\\\left(\\\\alpha_2 \\\\frac{2F\\\\hat{\\\\phi}_c}{RT}\\\\hat{\\\\phi}_{mf} \\\\right)\n",
    "\n",
    "        .. math::\n",
    "            \\\\hat{k}_{R3} = k_3^0 \\\\exp\\\\left(\\\\alpha_3 \\\\frac{(3-\\\\delta)F\\\\hat{\\\\phi}_c}{RT}\\\\hat{\\\\phi}_{fs} \\\\right)\n",
    "\n",
    "        .. math::\n",
    "            \\\\hat{k}_{R4} = k_4^0\n",
    "\n",
    "        .. math::\n",
    "            \\\\hat{k}_{R5} = k_5^0 (c_{H^+})^n\n",
    "\n",
    "        .. math::\n",
    "            \\\\hat{k}_{TP} = k_{tp}^0 \\\\hat{c}_h c_c \\\\exp\\\\left(\\\\alpha_{tp}\\\\frac{F\\\\hat{\\\\phi}_c}{RT}\\\\hat{\\\\phi}_{fs}\\\\right)\n",
    "\n",
    "        .. math::\n",
    "            \\\\hat{k}_{O2} = k_{o2}^0 \\\\exp\\\\left(\\\\alpha_{o2}\\\\frac{2F\\\\hat{\\\\phi}_c}{RT} \\\\left(\\\\hat{\\\\phi}_{ext} - \\\\hat{\\\\phi}_{o2,eq}\\\\right) \\\\right)\n",
    "\n",
    "        where:\n",
    "        - :math:`\\\\hat{\\\\phi}_{mf}` is the dimensionless potential at metal/film interface\n",
    "        - :math:`\\\\hat{\\\\phi}_{fs}` is the dimensionless potential at film/solution interface\n",
    "        - :math:`\\\\alpha_i, \\\\beta_i` are charge transfer coefficients\n",
    "\n",
    "        Args:\n",
    "            t: Time tensor (dimensionless)\n",
    "            E: Applied potential tensor\n",
    "            networks: NetworkManager instance\n",
    "            single: Whether computing for single point or batch\n",
    "\n",
    "        Returns:\n",
    "            Tuple of rate constants (k1, k2, k3, k4, k5, ktp, ko2)\n",
    "        \"\"\"\n",
    "        if single:\n",
    "            batch_size = 1\n",
    "            x_mf = torch.zeros(1, 1, device=device)\n",
    "        else:\n",
    "            batch_size = t.shape[0]\n",
    "            x_mf = torch.zeros(batch_size, 1, device=device)\n",
    "\n",
    "        # Get potentials at interfaces\n",
    "        inputs_mf = torch.cat([x_mf, t, E], dim=1)\n",
    "        u_mf = u_net(inputs_mf)  # φ̂_mf\n",
    "\n",
    "        # Get film thickness\n",
    "        L_inputs = torch.cat([t, E], dim=1)\n",
    "        L_pred = L_net(L_inputs)\n",
    "\n",
    "\n",
    "        x_fs = L_pred\n",
    "\n",
    "        inputs_fs = torch.cat([x_fs, t, E], dim=1)\n",
    "        u_fs = u_net(inputs_fs)  # φ̂_fs\n",
    "\n",
    "        # Compute rate constants using equations above\n",
    "        F_RT = F * phic / (R * T)\n",
    "\n",
    "        # k₁: Cation vacancy generation at m/f interface\n",
    "        k1 = k1_0 * torch.exp(alpha_cv * 3 * F_RT * u_mf)\n",
    "\n",
    "        # k₂: Anion vacancy generation at m/f interface\n",
    "        k2 = k2_0 * torch.exp(alpha_av * 2 * F_RT * u_mf)\n",
    "\n",
    "        # k₃: Cation vacancy consumption at f/s interface\n",
    "        k3 = k3_0 * torch.exp(beta_cv * (3 - delta3) * F_RT * u_fs)\n",
    "\n",
    "        # k₄: Chemical reaction (potential independent)\n",
    "        k4 = k4_0\n",
    "\n",
    "        # k₅: Chemical dissolution\n",
    "        k5 = k5_0 * c_H\n",
    "\n",
    "        return k1, k2, k3, k4, k5\n",
    "\n",
    "def compute_pde_residuals(x: torch.Tensor, t: torch.Tensor, E: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Compute PDE residuals for all governing equations.\n",
    "\n",
    "        **Cation Vacancy Conservation (Dimensionless Nernst-Planck):**\n",
    "\n",
    "        .. math::\n",
    "            \\\\frac{\\\\partial \\\\hat{c}_{cv}}{\\\\partial \\\\hat{t}} =\n",
    "            \\\\frac{D_{cv}\\\\hat{t}_c}{\\\\hat{L}_c^2}\\\\frac{\\\\partial^2 \\\\hat{c}_{cv}}{\\\\partial \\\\hat{x}^2} +\n",
    "            \\\\frac{U_{cv}\\\\hat{t}_c\\\\hat{\\\\phi}_c}{\\\\hat{L}_c^2}\\\\frac{\\\\partial \\\\hat{\\\\phi}}{\\\\partial \\\\hat{x}}\\\\frac{\\\\partial \\\\hat{c}_{cv}}{\\\\partial \\\\hat{x}} +\n",
    "            \\\\frac{U_{cv}\\\\hat{t}_c\\\\hat{\\\\phi}_c}{\\\\hat{L}_c^2}\\\\hat{c}_{cv}\\\\frac{\\\\partial^2 \\\\hat{\\\\phi}}{\\\\partial \\\\hat{x}^2}\n",
    "\n",
    "        **Anion Vacancy Conservation (Dimensionless Nernst-Planck):**\n",
    "\n",
    "        .. math::\n",
    "            \\\\frac{\\\\partial \\\\hat{c}_{av}}{\\\\partial \\\\hat{t}} =\n",
    "            \\\\frac{D_{av}\\\\hat{t}_c}{\\\\hat{L}_c^2}\\\\frac{\\\\partial^2 \\\\hat{c}_{av}}{\\\\partial \\\\hat{x}^2} +\n",
    "            \\\\frac{U_{av}\\\\hat{t}_c\\\\hat{\\\\phi}_c}{\\\\hat{L}_c^2}\\\\frac{\\\\partial \\\\hat{\\\\phi}}{\\\\partial \\\\hat{x}}\\\\frac{\\\\partial \\\\hat{c}_{av}}{\\\\partial \\\\hat{x}} +\n",
    "            \\\\frac{U_{av}\\\\hat{t}_c\\\\hat{\\\\phi}_c}{\\\\hat{L}_c^2}\\\\hat{c}_{av}\\\\frac{\\\\partial^2 \\\\hat{\\\\phi}}{\\\\partial \\\\hat{x}^2}\n",
    "\n",
    "        **Hole Conservation (Quasi-Steady State):**\n",
    "\n",
    "        .. math::\n",
    "            0 = \\\\frac{D_h\\\\hat{c}_{h,c}}{\\\\hat{L}_c^2}\\\\frac{\\\\partial^2 \\\\hat{c}_h}{\\\\partial \\\\hat{x}^2} +\n",
    "            \\\\frac{FD_h\\\\hat{\\\\phi}_c\\\\hat{c}_{h,c}}{RT\\\\hat{L}_c^2}\\\\frac{\\\\partial \\\\hat{\\\\phi}}{\\\\partial \\\\hat{x}}\\\\frac{\\\\partial \\\\hat{c}_h}{\\\\partial \\\\hat{x}} +\n",
    "            \\\\frac{FD_h\\\\hat{\\\\phi}_c\\\\hat{c}_{h,c}}{RT\\\\hat{L}_c^2}\\\\hat{c}_h\\\\frac{\\\\partial^2 \\\\hat{\\\\phi}}{\\\\partial \\\\hat{x}^2}\n",
    "\n",
    "        **Poisson's Equation (Dimensionless):**\n",
    "\n",
    "        .. math::\n",
    "            \\\\frac{\\\\partial^2 \\\\hat{\\\\phi}}{\\\\partial \\\\hat{x}^2} =\n",
    "            -\\\\frac{F\\\\hat{L}_c^2\\\\hat{c}_c}{\\\\hat{\\\\phi}_c\\\\varepsilon_f}\\\\left(z_{av}\\\\hat{c}_{av} + z_{cv}\\\\hat{c}_{cv}\\\\right)\n",
    "\n",
    "        Args:\n",
    "            x: Spatial coordinates (dimensionless)\n",
    "            t: Time coordinates (dimensionless)\n",
    "            E: Applied potential\n",
    "            networks: NetworkManager instance\n",
    "\n",
    "        Returns:\n",
    "            Tuple of residuals: (cv_residual, av_residual, h_residual, poisson_residual)\n",
    "        \"\"\"\n",
    "        # Get all gradients using the gradient computer\n",
    "        grads = compute_gradients(x, t, E)\n",
    "\n",
    "        # Cation vacancy residual - implements equation above\n",
    "        cv_residual = (grads.c_cv_t -\n",
    "                       (D_cv * tc / lc ** 2) * grads.c_cv_xx -\n",
    "                       (U_cv * tc * phic / lc ** 2) *\n",
    "                       grads.phi_x * grads.c_cv_x -\n",
    "                       (U_cv * tc * phic / lc ** 2) *\n",
    "                       grads.c_cv * grads.phi_xx)\n",
    "\n",
    "        # Anion vacancy residual - implements equation above\n",
    "        av_residual = (grads.c_av_t -\n",
    "                       (D_av * tc / lc ** 2) * grads.c_av_xx -\n",
    "                       (U_av * tc * phic / lc ** 2) *\n",
    "                       grads.phi_x * grads.c_av_x -\n",
    "                       (U_av * tc * phic / lc ** 2) *\n",
    "                       grads.c_av * grads.phi_xx)\n",
    "\n",
    "        # Poisson residual - implements equation above\n",
    "        poisson_residual = (grads.phi_xx +\n",
    "                            (F * lc ** 2 * cc /\n",
    "                             (phic * epsilonf)) *\n",
    "                            (z_av * grads.c_av + z_cv * grads.c_cv))\n",
    "\n",
    "        return cv_residual, av_residual, poisson_residual\n",
    "\n",
    "\n",
    "def compute_interior_loss(x: torch.Tensor, t: torch.Tensor, E: torch.Tensor,\n",
    "                          return_residuals: bool = False) -> Union[Tuple[torch.Tensor, Dict[str, torch.Tensor]],\n",
    "Tuple[torch.Tensor, Dict[str, torch.Tensor], Dict[str, torch.Tensor]]]:\n",
    "    \"\"\"\n",
    "    Compute interior PDE residual losses.\n",
    "\n",
    "    See compute_pde_residuals for mathematics of residual calculations\n",
    "\n",
    "    Args:\n",
    "        x: Spatial coordinates\n",
    "        t: Time coordinates\n",
    "        E: Applied potential\n",
    "        networks: NetworkManager instance\n",
    "        physics: ElectrochemicalPhysics instance\n",
    "        return_residuals: If True, also return raw residuals for NTK computation\n",
    "\n",
    "    Returns:\n",
    "        If return_residuals=False: Tuple of (total_interior_loss, individual_losses_dict)\n",
    "        If return_residuals=True: Tuple of (total_interior_loss, individual_losses_dict, residuals_dict)\n",
    "    \"\"\"\n",
    "    # Compute PDE residuals using physics module\n",
    "    cv_residual, av_residual, poisson_residual = compute_pde_residuals(x, t, E)\n",
    "\n",
    "    # Calculate individual losses\n",
    "    cv_pde_loss = torch.mean(cv_residual ** 2)\n",
    "    av_pde_loss = torch.mean(av_residual ** 2)\n",
    "    poisson_pde_loss = torch.mean(poisson_residual ** 2)\n",
    "\n",
    "    # Total interior loss\n",
    "    total_interior_loss = cv_pde_loss + av_pde_loss + poisson_pde_loss\n",
    "\n",
    "    individual_losses = {\n",
    "        'cv_pde': cv_pde_loss,\n",
    "        'av_pde': av_pde_loss,\n",
    "        'poisson_pde': poisson_pde_loss\n",
    "    }\n",
    "\n",
    "    if return_residuals:\n",
    "        residuals = {\n",
    "            'cv_pde': cv_residual,\n",
    "            'av_pde': av_residual,\n",
    "            'poisson_pde': poisson_residual\n",
    "        }\n",
    "        return total_interior_loss, individual_losses, residuals\n",
    "    else:\n",
    "        return total_interior_loss, individual_losses\n",
    "\n",
    "def compute_boundary_loss(x: torch.Tensor, t: torch.Tensor, E: torch.Tensor,\n",
    "                          return_residuals: bool = False) -> Union[Tuple[torch.Tensor, Dict[str, torch.Tensor]],\n",
    "Tuple[torch.Tensor, Dict[str, torch.Tensor], torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Compute boundary condition losses.\n",
    "     **Boundary Conditions:**\n",
    "\n",
    "    **Metal/Film Interface (x̂ = 0):**\n",
    "\n",
    "    *Cation Vacancy Flux:*\n",
    "\n",
    "    .. math::\n",
    "        -D_{cv}\\\\frac{\\\\partial \\\\hat{c}_{cv}}{\\\\partial \\\\hat{x}} = \\\\hat{k}_1 - \\\\left(U_{cv}\\\\frac{\\\\partial \\\\hat{\\\\phi}}{\\\\partial \\\\hat{x}} - \\\\frac{d\\\\hat{L}}{d\\\\hat{t}}\\\\right)\\\\hat{c}_{cv}\n",
    "\n",
    "    *Anion Vacancy Flux:*\n",
    "\n",
    "    .. math::\n",
    "        -D_{av}\\\\frac{\\\\partial \\\\hat{c}_{av}}{\\\\partial \\\\hat{x}} = \\\\frac{4}{3}\\\\hat{k}_2 + \\\\left(U_{av}\\\\frac{\\\\partial \\\\hat{\\\\phi}}{\\\\partial \\\\hat{x}} - \\\\frac{d\\\\hat{L}}{d\\\\hat{t}}\\\\right)\\\\hat{c}_{av}\n",
    "\n",
    "    *Potential Boundary:*\n",
    "\n",
    "    .. math::\n",
    "        \\\\varepsilon_f \\\\frac{\\\\partial \\\\hat{\\\\phi}}{\\\\partial \\\\hat{x}} = \\\\frac{\\\\varepsilon_{Ddl}(\\\\hat{\\\\phi} - \\\\hat{E})}{\\\\hat{d}_{Ddl}}\n",
    "\n",
    "    **Film/Solution Interface (x̂ = L̂):**\n",
    "\n",
    "    *Cation Vacancy Flux:*\n",
    "\n",
    "    .. math::\n",
    "        -D_{cv}\\\\frac{\\\\partial \\\\hat{c}_{cv}}{\\\\partial \\\\hat{x}} = \\\\left(\\\\hat{k}_3 - U_{cv}\\\\frac{\\\\partial \\\\hat{\\\\phi}}{\\\\partial \\\\hat{x}}\\\\right)\\\\hat{c}_{cv}\n",
    "\n",
    "    *Anion Vacancy Flux:*\n",
    "\n",
    "    .. math::\n",
    "        -D_{av}\\\\frac{\\\\partial \\\\hat{c}_{av}}{\\\\partial \\\\hat{x}} = \\\\left(\\\\hat{k}_4 - U_{av}\\\\frac{\\\\partial \\\\hat{\\\\phi}}{\\\\partial \\\\hat{x}}\\\\right)\\\\hat{c}_{av}\n",
    "\n",
    "    *Hole Flux:*\n",
    "\n",
    "    .. math::\n",
    "        D_h\\\\frac{\\\\partial \\\\hat{c}_h}{\\\\partial \\\\hat{x}} = \\\\hat{q}\\\\hat{c}_h\n",
    "\n",
    "    where :math:`\\\\hat{q} = -(\\\\hat{k}_{tp} + \\\\frac{FD_h}{RT}\\\\frac{\\\\partial \\\\hat{\\\\phi}}{\\\\partial \\\\hat{x}})` for :math:`\\\\hat{c}_h > 10^{-9}`\n",
    "\n",
    "    *Potential Boundary:*\n",
    "\n",
    "    .. math::\n",
    "        \\\\varepsilon_f \\\\frac{\\\\partial \\\\hat{\\\\phi}}{\\\\partial \\\\hat{x}} = \\\\varepsilon_{Ddl}\\\\hat{\\\\phi}\n",
    "    Args:\n",
    "        x: Boundary spatial coordinates\n",
    "        t: Time coordinates\n",
    "        E: Applied potential\n",
    "        networks: NetworkManager instance\n",
    "        physics: ElectrochemicalPhysics instance\n",
    "        return_residuals: If True, also return raw residuals for NTK computation\n",
    "\n",
    "    Returns:\n",
    "        If return_residuals=False: Tuple of (total_boundary_loss, individual_losses_dict)\n",
    "        If return_residuals=True: Tuple of (total_boundary_loss, individual_losses_dict, combined_residuals)\n",
    "    \"\"\"\n",
    "    batch_size = x.shape[0]\n",
    "    half_batch = batch_size // 2\n",
    "\n",
    "    # Split into metal/film and film/solution interfaces\n",
    "    x_mf = x[:half_batch]\n",
    "    x_fs = x[half_batch:]\n",
    "    t_mf = t[:half_batch]\n",
    "    t_fs = t[half_batch:]\n",
    "    E_mf = E[:half_batch]\n",
    "    E_fs = E[half_batch:]\n",
    "\n",
    "    # Predict L and compute derivative for boundary fluxes\n",
    "    L_input = torch.cat([t, E], dim=1)\n",
    "    L_pred = L_net(L_input)\n",
    "    L_pred_t = _grad(L_pred, t)\n",
    "    L_pred_t_mf = L_pred_t[:half_batch]\n",
    "\n",
    "    # Metal/film interface conditions\n",
    "    inputs_mf = torch.cat([x_mf, t_mf, E_mf], dim=1)\n",
    "    u_pred_mf = u_net(inputs_mf)\n",
    "    u_pred_mf_x = _grad(u_pred_mf, x_mf)\n",
    "\n",
    "    # CV at m/f interface\n",
    "    cv_pred_mf = cv_net(inputs_mf)\n",
    "    cv_pred_mf_x = _grad(cv_pred_mf, x_mf)\n",
    "    cv_mf_residual = ((-D_cv * cc / lc) * cv_pred_mf_x -\n",
    "                      k1_0 * torch.exp(\n",
    "                alpha_cv * phic * (E_mf / phic - u_pred_mf)) -\n",
    "                      (U_cv * phic / lc * u_pred_mf_x -\n",
    "                       lc / tc * L_pred_t_mf) * cc * cv_pred_mf)\n",
    "    cv_mf_loss = torch.mean(cv_mf_residual ** 2)\n",
    "\n",
    "    # AV at m/f interface\n",
    "    av_pred_mf = av_net(inputs_mf)\n",
    "    av_pred_mf_x = _grad(av_pred_mf, x_mf)\n",
    "    av_mf_residual = ((-D_av * cc / lc) * av_pred_mf_x -\n",
    "                      (4 / 3) * k2_0 * torch.exp(\n",
    "                alpha_av * phic * (E_mf / phic - u_pred_mf)) -\n",
    "                      (U_av * phic / lc * u_pred_mf_x -\n",
    "                       lc / tc * L_pred_t_mf) * av_pred_mf)\n",
    "    av_mf_loss = torch.mean(av_mf_residual ** 2)\n",
    "\n",
    "    # Potential at m/f interface\n",
    "    u_mf_residual = ((eps_film * phic /lc * u_pred_mf_x) -\n",
    "                     eps_Ddl * phic * (\n",
    "                             u_pred_mf - E_mf / phic) / d_Ddl)\n",
    "    u_mf_loss = torch.mean(u_mf_residual ** 2)\n",
    "\n",
    "    # Film/solution interface conditions\n",
    "    inputs_fs = torch.cat([x_fs, t_fs, E_fs], dim=1)\n",
    "    u_pred_fs = u_net(inputs_fs)\n",
    "    u_pred_fs_x = _grad(u_pred_fs, x_fs)\n",
    "\n",
    "    # CV at f/s interface\n",
    "    cv_pred_fs = cv_net(inputs_fs)\n",
    "    cv_pred_fs_x = _grad(cv_pred_fs, x_fs)\n",
    "    cv_fs_residual = ((-D_cv * cc / lc) * cv_pred_fs_x -\n",
    "                      (k3_0 * torch.exp(beta_cv * phic * u_pred_fs) -\n",
    "                       U_cv * phic / lc * u_pred_fs_x) * cv_pred_fs * cc)\n",
    "    cv_fs_loss = torch.mean(cv_fs_residual ** 2)\n",
    "\n",
    "    # AV at f/s interface\n",
    "    av_pred_fs = av_net(inputs_fs)\n",
    "    av_pred_fs_x = _grad(av_pred_fs, x_fs)\n",
    "    av_fs_residual = ((-D_av * cc / lc) * av_pred_fs_x -\n",
    "                      (k4_0 * torch.exp(alpha_av * u_pred_fs) -\n",
    "                       U_av * phic / lc * u_pred_fs_x) * av_pred_fs * cc)\n",
    "    av_fs_loss = torch.mean(av_fs_residual ** 2)\n",
    "\n",
    "    # Potential at f/s interface\n",
    "    u_fs_residual = ((eps_film * phic / lc * u_pred_fs_x) -\n",
    "                     (eps_Ddl * phic * u_pred_fs))\n",
    "    u_fs_loss = torch.mean(u_fs_residual ** 2)\n",
    "\n",
    "    # Total boundary loss\n",
    "    total_boundary_loss = cv_mf_loss + u_mf_loss + cv_fs_loss + av_fs_loss + u_fs_loss + av_mf_loss \n",
    "\n",
    "    individual_losses = {\n",
    "        'cv_mf_bc': cv_mf_loss,\n",
    "        'av_mf_bc': av_mf_loss,\n",
    "        'u_mf_bc': u_mf_loss,\n",
    "        'cv_fs_bc': cv_fs_loss,\n",
    "        'av_fs_bc': av_fs_loss,\n",
    "        'u_fs_bc': u_fs_loss,\n",
    "    }\n",
    "\n",
    "    if return_residuals:\n",
    "        # Combine all residuals into single tensor for NTK computation\n",
    "\n",
    "        residuals_dict = {'cv_mf_bc':cv_mf_residual, 'av_mf_bc':av_mf_residual, 'u_mf_bc':u_mf_residual, \n",
    "                    'cv_fs_bc':cv_fs_residual, 'av_fs_bc':av_mf_residual, 'u_fs_bc':u_fs_residual}\n",
    "        combined_residuals = torch.cat([\n",
    "            cv_mf_residual, cv_fs_residual,\n",
    "            av_mf_residual, av_fs_residual,\n",
    "        ])\n",
    "        return total_boundary_loss, individual_losses, combined_residuals,residuals_dict\n",
    "    else:\n",
    "        return total_boundary_loss, individual_losses\n",
    "\n",
    "def compute_initial_loss(x: torch.Tensor, t: torch.Tensor, E: torch.Tensor,\n",
    "                         return_residuals: bool = False) -> Union[Tuple[torch.Tensor, Dict[str, torch.Tensor]],\n",
    "Tuple[torch.Tensor, Dict[str, torch.Tensor], torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Compute initial condition losses.\n",
    "\n",
    "    **Initial Conditions (t̂ = 0):**\n",
    "\n",
    "    **Film Thickness:**\n",
    "\n",
    "    .. math::\n",
    "        \\\\hat{L}(0) = \\\\frac{L_0}{\\\\hat{L}_c}\n",
    "\n",
    "    **Cation Vacancy Concentration:**\n",
    "\n",
    "    .. math::\n",
    "        \\\\hat{c}_{cv}(\\\\hat{x}, 0) = 0\n",
    "\n",
    "    .. math::\n",
    "        \\\\frac{\\\\partial \\\\hat{c}_{cv}}{\\\\partial \\\\hat{t}}\\\\bigg|_{\\\\hat{t}=0} = 0\n",
    "\n",
    "    **Anion Vacancy Concentration:**\n",
    "\n",
    "    .. math::\n",
    "        \\\\hat{c}_{av}(\\\\hat{x}, 0) = 0\n",
    "\n",
    "    .. math::\n",
    "        \\\\frac{\\\\partial \\\\hat{c}_{av}}{\\\\partial \\\\hat{t}}\\\\bigg|_{\\\\hat{t}=0} = 0\n",
    "\n",
    "    **Potential Distribution:**\n",
    "\n",
    "    .. math::\n",
    "        \\\\hat{\\\\phi}(\\\\hat{x}, 0) = \\\\frac{\\\\hat{E}}{\\\\hat{\\\\phi}_c} - \\\\frac{10^7 \\\\hat{L}_c}{\\\\hat{\\\\phi}_c}\\\\hat{x}\n",
    "\n",
    "    .. math::\n",
    "        \\\\frac{\\\\partial \\\\hat{\\\\phi}}{\\\\partial \\\\hat{t}}\\\\bigg|_{\\\\hat{t}=0} = 0\n",
    "\n",
    "    **Hole Concentration:**\n",
    "\n",
    "    .. math::\n",
    "        \\\\hat{c}_h(\\\\hat{x}, 0) = \\\\frac{c_{h0}}{\\\\hat{c}_{h,c}} = 1\n",
    "\n",
    "    .. math::\n",
    "        \\\\frac{\\\\partial \\\\hat{c}_h}{\\\\partial \\\\hat{t}}\\\\bigg|_{\\\\hat{t}=0} = 0\n",
    "\n",
    "    Args:\n",
    "        x: Spatial coordinates\n",
    "        t: Time coordinates (should be zeros)\n",
    "        E: Applied potential\n",
    "        networks: NetworkManager instance\n",
    "        physics: ElectrochemicalPhysics instance\n",
    "        return_residuals: If True, also return raw residuals for NTK computation\n",
    "\n",
    "    Returns:\n",
    "        If return_residuals=False: Tuple of (total_initial_loss, individual_losses_dict)\n",
    "        If return_residuals=True: Tuple of (total_initial_loss, individual_losses_dict, combined_residuals)\n",
    "    \"\"\"\n",
    "    L_input = torch.cat([t, E], dim=1)\n",
    "    L_initial_pred = L_net(L_input)\n",
    "    inputs = torch.cat([x, t, E], dim=1)\n",
    "\n",
    "    # Film thickness initial condition\n",
    "    L_initial_residual = L_initial_pred - L_initial / lc\n",
    "    L_initial_loss = torch.mean(L_initial_residual ** 2)\n",
    "\n",
    "    # Cation vacancy initial conditions\n",
    "    cv_initial_pred = cv_net(inputs)\n",
    "    cv_initial_t = _grad(cv_initial_pred, t)\n",
    "    cv_initial_residual = cv_initial_pred + cv_initial_t\n",
    "    cv_initial_loss = torch.mean(cv_initial_pred**2) + torch.mean(cv_initial_t**2)\n",
    "\n",
    "    # Anion vacancy initial conditions\n",
    "    av_initial_pred = av_net(inputs)\n",
    "    av_initial_t = _grad(av_initial_pred, t)\n",
    "    av_initial_residual = av_initial_pred + av_initial_t\n",
    "    av_initial_loss = torch.mean(av_initial_pred**2) + torch.mean(av_initial_t**2)\n",
    "\n",
    "    # Potential initial conditions\n",
    "    u_initial_pred = u_net(inputs)\n",
    "    u_initial_t = _grad(u_initial_pred, t)\n",
    "    poisson_initial_residual = (u_initial_pred - (\n",
    "            (E / phic) - (1e7 * (lc / phic) * x))) + u_initial_t\n",
    "    poisson_initial_loss = torch.mean((u_initial_pred - (\n",
    "            (E / phic) - (1e7 * (lc / phic) * x)))**2) + torch.mean(u_initial_t**2)\n",
    "\n",
    "    # Total initial loss\n",
    "    total_initial_loss = cv_initial_loss + av_initial_loss + poisson_initial_loss + L_initial_loss\n",
    "\n",
    "    individual_losses = {\n",
    "        'cv_ic': cv_initial_loss,\n",
    "        'av_ic': av_initial_loss,\n",
    "        'poisson_ic': poisson_initial_loss,\n",
    "        'L_ic': L_initial_loss\n",
    "    }\n",
    "\n",
    "    if return_residuals:\n",
    "        # Combine all residuals into single tensor for NTK computation\n",
    "        residual_dict = {'cv_ic':cv_initial_residual, 'av_ic':av_initial_residual,'poisson_ic':poisson_initial_residual, 'L_ic':L_initial_residual}\n",
    "        combined_residuals = torch.cat([\n",
    "            L_initial_residual,\n",
    "            cv_initial_residual,\n",
    "            av_initial_residual,\n",
    "            poisson_initial_residual,\n",
    "        ])\n",
    "        return total_initial_loss, individual_losses, combined_residuals,residual_dict\n",
    "    else:\n",
    "        return total_initial_loss, individual_losses\n",
    "\n",
    "def compute_film_physics_loss(t: torch.Tensor, E: torch.Tensor,\n",
    "                              return_residuals: bool = False) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Compute film growth physics loss.\n",
    "\n",
    "     **Film Growth Equation:**\n",
    "\n",
    "    .. math::\n",
    "        \\\\frac{dL}{dt} = \\\\Omega (k_2 - k_5)\n",
    "\n",
    "    **Dimensionless Form:**\n",
    "\n",
    "    .. math::\n",
    "        \\\\frac{d\\\\hat{L}}{d\\\\hat{t}} = \\\\frac{\\\\hat{t}_c \\\\Omega}{\\\\hat{L}_c} (k_2 - k_5)\n",
    "\n",
    "\n",
    "    Args:\n",
    "        t: Time coordinates\n",
    "        E: Applied potential\n",
    "        networks: NetworkManager instance\n",
    "        physics: ElectrochemicalPhysics instance\n",
    "        return_residuals: If True, also return raw residuals for NTK computation\n",
    "\n",
    "    Returns:\n",
    "        If return_residuals=False: Film physics loss tensor\n",
    "        If return_residuals=True: Tuple of (film_physics_loss, residuals)\n",
    "    \"\"\"\n",
    "    inputs = torch.cat([t, E], dim=1)\n",
    "    L_pred = L_net(inputs)\n",
    "\n",
    "    # Get rate constants\n",
    "    k1, k2, k3, k4, k5 = compute_rate_constants(t, E)\n",
    "\n",
    "    # Compute predicted and physics-based dL/dt\n",
    "    dl_dt_pred = _grad(L_pred, t)\n",
    "    dL_dt_physics = (1 /lc) * tc * Omega * (k2 - k5) #k_2 being problematic, we see this in polarization curve would make sense if it happens here too\n",
    "\n",
    "    # Compute residual\n",
    "    film_residual = dl_dt_pred - dL_dt_physics\n",
    "    film_loss = torch.mean(film_residual ** 2)\n",
    "\n",
    "    if return_residuals:\n",
    "        return film_loss, film_residual\n",
    "    else:\n",
    "        return film_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6063362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the total loss with augmented lagrangian\n",
    "\n",
    "#Create all the lambdas we need\n",
    "l_cv_mf = torch.zeros(1024, device=device, requires_grad=True)\n",
    "l_av_mf = torch.zeros(1024, device=device, requires_grad=True)\n",
    "l_cv_fs = torch.zeros(1024, device=device, requires_grad=True)\n",
    "l_av_fs = torch.zeros(1024, device=device, requires_grad=True)\n",
    "l_u_fs = torch.zeros(1024, device=device, requires_grad=True)\n",
    "l_cv_in = torch.zeros(1024, device=device, requires_grad=True)\n",
    "l_av_in = torch.zeros(1024, device=device, requires_grad=True)\n",
    "l_u_in = torch.zeros(1024, device=device, requires_grad=True)\n",
    "l_film_in = torch.zeros(1024, device=device, requires_grad=True)\n",
    "l_film = torch.zeros(2048, device=device, requires_grad=True)\n",
    "\n",
    "def total_loss():\n",
    "    beta = 500.0 # AL beta parameter\n",
    "    #Investigate using one E for all the different samples, this might help a lot. Could do an easy fix here\n",
    "    x_interior, t_interior, E_interior = sample_interior_points()\n",
    "    x_boundary, t_boundary, E_boundary = sample_boundary_points()\n",
    "    x_inital, t_initial, E_initial = sample_initial_points()\n",
    "    t_film, E_film = sample_film_physics_points()\n",
    "\n",
    "    total_interior_loss, individual_losses, residuals_interior = compute_interior_loss(x_interior,t_interior,E_interior,return_residuals=True)\n",
    "    total_boundary_loss, boundary_losses, combined_residuals_bc,residuals_dict_bc = compute_boundary_loss(x_boundary,t_boundary,E_boundary,return_residuals=True)\n",
    "    total_initial_loss, initial_losses, combined_residuals_ic,residuals_dict_ic = compute_initial_loss(x_inital,t_initial,E_initial,return_residuals=True)\n",
    "    film_loss, film_residual = compute_film_physics_loss(t_film,E_film,return_residuals=True)\n",
    "\n",
    "    # Augmented Lagrangian Loss: L = objective + β‖C‖² + ⟨λ,C⟩\n",
    "    loss = total_interior_loss \n",
    "\n",
    "    # Boundary constraints\n",
    "    loss += beta*boundary_losses[\"cv_mf_bc\"] + (l_cv_mf*residuals_dict_bc[\"cv_mf_bc\"]).mean()\n",
    "    loss += beta*boundary_losses[\"av_mf_bc\"] + (l_av_mf*residuals_dict_bc[\"av_mf_bc\"]).mean()\n",
    "    loss += beta*boundary_losses[\"cv_fs_bc\"] + (l_cv_fs*residuals_dict_bc[\"cv_fs_bc\"]).mean()\n",
    "    loss += beta*boundary_losses[\"av_fs_bc\"] + (l_av_fs*residuals_dict_bc[\"av_fs_bc\"]).mean()\n",
    "    loss += beta*boundary_losses[\"u_fs_bc\"] + (l_u_fs*residuals_dict_bc[\"u_fs_bc\"]).mean()\n",
    "\n",
    "    # Initial constraints  \n",
    "    loss += beta*initial_losses[\"cv_ic\"] + (l_cv_in*residuals_dict_ic[\"cv_ic\"]).mean()\n",
    "    loss += beta*initial_losses[\"av_ic\"] + (l_av_in*residuals_dict_ic[\"av_ic\"]).mean()\n",
    "    loss += beta*initial_losses[\"poisson_ic\"] + (l_u_in*residuals_dict_ic[\"poisson_ic\"]).mean()\n",
    "    loss += beta*initial_losses[\"L_ic\"] + (l_film_in*residuals_dict_ic[\"L_ic\"]).mean()\n",
    "\n",
    "    # Film physics constraint\n",
    "    loss += beta*film_loss + (l_film*film_residual).mean()\n",
    "    #should check if we need .view(-1)\n",
    "    #could experiment with making film physics an objective vs a constraint. Worth discussing with Conrard\n",
    "\n",
    "    return loss, total_interior_loss, total_boundary_loss, total_initial_loss, film_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e5cc647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb00e22ae9d4cc5bc886cfd5a02a270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Status:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:1996513.625, interior:1992528.5, boundary:0.004996717907488346, initial:1000.816650390625, film:2984.240478515625 at step:0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m loss, interior_loss, boundary_loss, initial_loss, film_loss = total_loss()\n\u001b[32m     22\u001b[39m loss_total = interior_loss + boundary_loss + initial_loss + film_loss\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m l_cv_mf.grad *= -\u001b[32m1\u001b[39m\n\u001b[32m     27\u001b[39m l_av_mf.grad *= -\u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/physicsOxy/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/physicsOxy/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/physicsOxy/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#main training loop\n",
    "\n",
    "optimizer=torch.optim.Adam([{'params': total_model_parameters}, {'params': l_cv_mf, 'lr':lbd_lr}, \\\n",
    "                                {'params': l_av_mf, 'lr':lbd_lr}, {'params': l_cv_fs, 'lr':lbd_lr},{'params': l_av_fs, 'lr':lbd_lr},{'params': l_u_fs, 'lr':lbd_lr}, \n",
    "                                {'params': l_cv_in, 'lr':lbd_lr},{'params': l_av_in, 'lr':lbd_lr},{'params': l_u_in, 'lr':lbd_lr},{'params': l_film_in, 'lr':lbd_lr},\n",
    "                                {'params': l_film, 'lr':lbd_lr}], lr=lr)\n",
    "\n",
    "loss_list = []\n",
    "interior_loss_list = []\n",
    "boundary_loss_list = []\n",
    "initial_loss_list = []\n",
    "film_loss_list = []\n",
    "\n",
    "for step in tqdm(range(max_steps),desc=\"Training Status\"):\n",
    "    cv_net.train()\n",
    "    av_net.train()\n",
    "    u_net.train()\n",
    "    L_net.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss, interior_loss, boundary_loss, initial_loss, film_loss = total_loss()\n",
    "    loss_total = interior_loss + boundary_loss + initial_loss + film_loss\n",
    "    loss.backward()\n",
    "\n",
    "\n",
    "    l_cv_mf.grad *= -1\n",
    "    l_av_mf.grad *= -1\n",
    "    l_cv_fs.grad *= -1\n",
    "    l_av_fs.grad *= -1\n",
    "    l_u_fs.grad *= -1\n",
    "    l_cv_in.grad *= -1\n",
    "    l_av_in.grad *= -1\n",
    "    l_u_in.grad *= -1\n",
    "    l_film_in.grad *= -1\n",
    "    l_film.grad *= -1\n",
    "\n",
    "\n",
    "    optimizer.step()\n",
    "        \n",
    "    loss_list.append(loss_total.item())\n",
    "    interior_loss_list.append(interior_loss.item())\n",
    "    boundary_loss_list.append(boundary_loss.item())\n",
    "    initial_loss_list.append(initial_loss.item())\n",
    "    film_loss_list.append(film_loss.item())\n",
    "\n",
    "    if step % print_freq == 0:\n",
    "        tqdm.write(f\"Total:{loss_total}, interior:{interior_loss}, boundary:{boundary_loss}, initial:{initial_loss}, film:{film_loss} at step:{step}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757334eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "window=100\n",
    "# Raw loss\n",
    "plt.plot(loss_list, alpha=0.3, color='lightblue', label='Raw Loss')\n",
    "\n",
    "# Moving average for smoother trend\n",
    "if len(loss_list) > window:\n",
    "    moving_avg = np.convolve(loss_list, np.ones(window)/window, mode='valid')\n",
    "    plt.plot(range(window-1, len(loss_list)), moving_avg, \n",
    "        color='red', linewidth=2, label=f'Moving Avg ({window})')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Training Step', fontsize=12)\n",
    "plt.ylabel('Total Loss (log scale)', fontsize=12)\n",
    "plt.title('PINNACLE Training Loss Evolution', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physicsOxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
