{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f67b3b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x71920c3425d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from typing import Dict, Any, Tuple, Union, NamedTuple\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(995) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "012854fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical constants\n",
    "F = 96485 # Faraday constant [C/mol]\n",
    "R = 8.3145 # Gas constant [J/(mol·K)]\n",
    "T = 603 # Temperature [K] - from Seyeux experiments\n",
    "N_V = 6.022e23 # ovogadro's number [mol⁻¹]\n",
    "\n",
    "# Diffusion coefficients [m²/s]\n",
    "D_vo = 5.30e-23 # Oxygen vacancy diffusion coefficient\n",
    "D_MCr = 5.0e-24 # Cation vacancy diffusion coefficient\n",
    "D_ICr = 1.0e-20 # Cation interstitial diffusion coefficient\n",
    "\n",
    "# Species charges (inferred from defect chemistry)\n",
    "z_ov = +2 # Oxygen vacancy charge\n",
    "z_MCr = -3 # Cation vacancy charge (V_Cr''')\n",
    "z_ICr = +3 # Cation interstitial charge (Cr_i•••)\n",
    "\n",
    "# Initial potentials [V]\n",
    "phi_f_i = 0.1 # Initial film potential\n",
    "phi_mf_0 = 0.001 # Metal/film interface potential  \n",
    "phi_fs_0 = 0.3 # Initial film/solution interface potential\n",
    "\n",
    "# Applied potential and distribution\n",
    "delta_V = 0.01 # Applied potential change [V]\n",
    "alpha = 0.5 # Potential distribution parameter\n",
    "x_d = 5.0e-8 # Decay length [m]\n",
    "\n",
    "# Alloy composition\n",
    "chi_Cr = 0.32 # Chromium mole fraction\n",
    "chi_Fe = 0.10 # Iron mole fraction\n",
    "chi_Ni = 0.58 # Nickel mole fraction\n",
    "\n",
    "# Gibbs free energies [J/mol] - for all reactions\n",
    "delta_G1 = -15000 # Oxygen vacancy formation at metal/film\n",
    "delta_G8 = -100000 # Oxygen vacancy reaction at film/solution\n",
    "delta_G2 = -90000 # Cation vacancy formation\n",
    "delta_G4 = -30000 # Cation vacancy dissolution\n",
    "delta_G6 = -85000 # Cation interstitial formation\n",
    "delta_G9 = 100000 # Related to cation transport\n",
    "delta_G11 = 30000 # Additional reaction energies\n",
    "delta_G13 = 10000\n",
    "delta_G10 = -1000\n",
    "delta_G12 = -6000\n",
    "delta_G14 = -3000\n",
    "delta_G3 = 85000\n",
    "delta_G5 = 10000\n",
    "delta_G7 = 10000\n",
    "\n",
    "# Dissolution parameters (if including dissolution)\n",
    "n = 3 # Reaction order\n",
    "k_0 = 8.40e16 # Pre-exponential factor [m⁻²s⁻¹]\n",
    "m = 1 # pH dependence order\n",
    "E_a = 54000 # Activation energy [J/mol]\n",
    "\n",
    "# Molar volume\n",
    "Omega = 1.4e-5 # [m³/mol]\n",
    "\n",
    "# Solution properties\n",
    "pH = 7.2 # From Seyeux Alloy 690 experiments\n",
    "c_H = 10**(-pH) * 1000 # Proton concentration [mol/m³]\n",
    "\n",
    "\n",
    "#Applied Potential [V]\n",
    "E_min = 0.0\n",
    "E_max = 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8debd5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define networks\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return torch.sigmoid(x)*x\n",
    "    \n",
    "\n",
    "class FFN(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully Connected Feed Forward Neural Network.\n",
    "    Args:\n",
    "        input_dim: Number of input features\n",
    "        output_dim: Number of output features  \n",
    "        hidden_layers: Number of hidden layers\n",
    "        layer_size: Size of each hidden layer\n",
    "        activation: Activation function name ('swish', 'swoosh', 'swash', 'squash_swish', 'relu', 'tanh')\n",
    "        initialize_weights: Whether to apply Xovier initialization\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 2,\n",
    "        output_dim: int = 1,\n",
    "        hidden_layers: int = 5,\n",
    "        layer_size: int = 20,\n",
    "        activation: str = \"swish\",\n",
    "        initialize_weights: bool = False\n",
    "    ):\n",
    "        super(FFN, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = hidden_layers\n",
    "        self.layer_size = layer_size\n",
    "        self.activation = Swish()\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_dim, self.layer_size)\n",
    "        \n",
    "        # Hidden layers\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(self.layer_size, self.layer_size)\n",
    "            for _ in range(self.num_layers)  \n",
    "        ])\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(self.layer_size, output_dim)\n",
    "        \n",
    "        # Initialize weights\n",
    "        if initialize_weights:\n",
    "            self.initialize_weights()\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        \"\"\"Apply Xovier initialization to all linear layers\"\"\"\n",
    "        # Initialize input layer\n",
    "        nn.init.xavier_normal_(self.input_layer.weight)\n",
    "        nn.init.zeros_(self.input_layer.bias)\n",
    "        \n",
    "        # Initialize hidden layers\n",
    "        for layer in self.hidden_layers:\n",
    "            nn.init.xavier_normal_(layer.weight)\n",
    "            nn.init.zeros_(layer.bias)\n",
    "        \n",
    "        # Initialize output layer\n",
    "        nn.init.xavier_normal_(self.output_layer.weight)\n",
    "        nn.init.zeros_(self.output_layer.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.input_layer(x))\n",
    "        \n",
    "        for layer in self.hidden_layers: \n",
    "            x = self.activation(layer(x))\n",
    "        \n",
    "        return self.output_layer(x)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Single residual block: x + F(x)\"\"\"\n",
    "    def __init__(self, layer_size, activation):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.layer_size = layer_size\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Two layers in each residual block\n",
    "        self.linear1 = nn.Linear(layer_size, layer_size)\n",
    "        self.linear2 = nn.Linear(layer_size, layer_size)\n",
    "        \n",
    "    def initialize_weights(self):\n",
    "        nn.init.xavier_normal_(self.linear1.weight)\n",
    "        nn.init.zeros_(self.linear1.bias)\n",
    "        nn.init.xavier_normal_(self.linear2.weight)\n",
    "        nn.init.zeros_(self.linear2.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x  # Save input for residual connection\n",
    "        \n",
    "        # F(x) computation\n",
    "        out = self.activation(self.linear1(x))\n",
    "        out = self.linear2(out)  # No activation on final layer of block\n",
    "        \n",
    "        # Residual connection: x + F(x)\n",
    "        out = out + identity\n",
    "        \n",
    "        # Activation after residual connection\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class ResidualFFN(nn.Module):\n",
    "    def __init__(self, input_dim=3, output_dim=1, num_layers=8, layer_size=50, initialize_weights=False):\n",
    "        super(ResidualFFN, self).__init__()\n",
    "        self.layer_size = layer_size\n",
    "        self.num_layers = num_layers\n",
    "        self.activation = Swish()\n",
    "        \n",
    "        # Input projection to get to residual dimension\n",
    "        self.input_layer = nn.Linear(input_dim, self.layer_size)\n",
    "        \n",
    "        # Residual blocks\n",
    "        self.residual_layers = nn.ModuleList([\n",
    "            ResidualBlock(self.layer_size, self.activation)\n",
    "            for _ in range(self.num_layers)  \n",
    "        ])\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(self.layer_size, output_dim)\n",
    "        \n",
    "        if initialize_weights:\n",
    "            self.initialize_weights()\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        \"\"\"Apply Xavier initialization to all linear layers\"\"\"\n",
    "        nn.init.xavier_normal_(self.input_layer.weight)\n",
    "        nn.init.zeros_(self.input_layer.bias)\n",
    "        \n",
    "        for block in self.residual_layers:\n",
    "            block.initialize_weights()\n",
    "        \n",
    "        nn.init.xavier_normal_(self.output_layer.weight)\n",
    "        nn.init.zeros_(self.output_layer.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input projection\n",
    "        x = self.activation(self.input_layer(x))\n",
    "        \n",
    "        # Residual blocks\n",
    "        for residual_layer in self.residual_layers:\n",
    "            x = residual_layer(x)\n",
    "        \n",
    "        # Output\n",
    "        return self.output_layer(x)\n",
    "    \n",
    "\n",
    "ov_net = ResidualFFN(input_dim=2, output_dim=1, num_layers=3, layer_size=20)\n",
    "cv_net = ResidualFFN(input_dim=2, output_dim=1, num_layers=3, layer_size=20)\n",
    "cir_net = ResidualFFN(input_dim=2, output_dim=1, num_layers=3, layer_size=20)\n",
    "L_net = ResidualFFN(input_dim=1, output_dim=1, num_layers=3, layer_size=20)\n",
    "cv_net.to(device)\n",
    "ov_net.to(device)\n",
    "cir_net.to(device)\n",
    "L_net.to(device)\n",
    "\n",
    "total_model_parameters = list(cv_net.parameters()) + list(ov_net.parameters()) + list(cir_net.parameters()) + list(L_net.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e7dd08d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient and sampling utils\n",
    "\n",
    "class GradientResults(NamedTuple):\n",
    "    \"\"\"\n",
    "    Container for gradient computation results.\n",
    "\n",
    "    Organizes all computed derivatives in a structured way for easy access.\n",
    "    \"\"\"\n",
    "    # Network predictions\n",
    "    c_cir: torch.Tensor # Cation Intersitial concentration\n",
    "    c_cv: torch.Tensor  # Cation vacancy concentration\n",
    "    c_ov: torch.Tensor  # Oxygen vacancy concentration\n",
    "\n",
    "    # Time derivatives\n",
    "    c_cir_t: torch.Tensor\n",
    "    c_cv_t: torch.Tensor  # ∂c_cv/∂t\n",
    "    c_ov_t: torch.Tensor  # ∂c_ov/∂t\n",
    "\n",
    "    # First spatial derivatives\n",
    "    c_cir_x: torch.Tensor\n",
    "    c_cv_x: torch.Tensor  # ∂c_cv/∂x\n",
    "    c_ov_x: torch.Tensor  # ∂c_ov/∂x\n",
    "\n",
    "    # Second spatial derivatives\n",
    "    c_cir_xx: torch.Tensor  \n",
    "    c_cv_xx: torch.Tensor  # ∂²c_cv/∂x²\n",
    "    c_ov_xx: torch.Tensor  # ∂²c_av/∂x²\n",
    "\n",
    "\n",
    "def _grad(x,dx):\n",
    "    \"\"\"Take the derrivative of x w.r.t dx\"\"\"\n",
    "\n",
    "    return torch.autograd.grad(x,dx,torch.ones_like(dx),create_graph=True,retain_graph=True)[0]\n",
    "\n",
    "def compute_gradients(x, t):\n",
    "    inputs = torch.cat([x, t], dim=1)\n",
    "\n",
    "    # Get network predictions\n",
    "    c_cir_raw = cir_net(inputs)\n",
    "    c_cv_raw = cv_net(inputs)\n",
    "    c_ov_raw = ov_net(inputs)\n",
    "\n",
    "\n",
    "    # Networks predict concentrations directly\n",
    "    c_cv = c_cv_raw\n",
    "    c_ov = c_ov_raw\n",
    "    c_cir = c_cir_raw\n",
    "\n",
    "    # Direct derivatives\n",
    "    c_cv_t = _grad(c_cv, t)\n",
    "    c_ov_t = _grad(c_ov, t)\n",
    "    c_cir_t = _grad(c_cir,t)\n",
    "\n",
    "    c_cv_x = _grad(c_cv, x)\n",
    "    c_ov_x = _grad(c_ov, x)\n",
    "    c_cir_x = _grad(c_cir,x)\n",
    "   \n",
    "    c_cv_xx = _grad(c_cv_x, x)\n",
    "    c_ov_xx = _grad(c_ov_x, x)\n",
    "    c_cir_xx = _grad(c_cir_x,x)\n",
    "\n",
    "    return GradientResults(\n",
    "        c_cir=c_cir, c_cv=c_cv, c_ov=c_ov,\n",
    "        c_cv_t=c_cv_t, c_ov_t=c_ov_t, c_cir_t = c_cir_t,\n",
    "        c_cir_x = c_cir_x, c_cv_x=c_cv_x, c_ov_x=c_ov_x, \n",
    "        c_cir_xx = c_cir_xx, c_cv_xx=c_cv_xx, c_ov_xx=c_ov_xx\n",
    "    )\n",
    "\n",
    "def sample_interior_points():\n",
    "    batch_size = 2048\n",
    "    t = torch.rand(batch_size, 1, device=device, requires_grad=True)\n",
    "    L_pred = L_net(t)  # L_net takes only time\n",
    "    x = torch.rand(batch_size, 1, device=device, requires_grad=True) * L_pred\n",
    "    return x, t\n",
    "\n",
    "def sample_boundary_points():\n",
    "    batch_size = 2 * 1024\n",
    "    t = torch.rand(batch_size, 1, device=device, requires_grad=True)\n",
    "    L_pred = L_net(t)\n",
    "    \n",
    "    half_batch = batch_size // 2\n",
    "    x_mf = torch.zeros(half_batch, 1, device=device, requires_grad=True)\n",
    "    x_fs = L_pred[half_batch:]\n",
    "    \n",
    "    x_boundary = torch.cat([x_mf, x_fs], dim=0)\n",
    "    t_boundary = torch.cat([t[:half_batch], t[half_batch:]], dim=0)\n",
    "    \n",
    "    return x_boundary, t_boundary\n",
    "\n",
    "def sample_film_physics_points():\n",
    "    batch_size = 2048\n",
    "    t = torch.rand(batch_size, 1, device=device, requires_grad=True)\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd92272a",
   "metadata": {},
   "source": [
    "## Mathematics of the Model Being Implemented\n",
    "\n",
    "### Interior Equations\n",
    "\\frac{\\partial C_{V_O}}{\\partial t} = D_{V_O} \\frac{\\partial^2 C_{V_O}}{\\partial x^2} + \\frac{D_{V_O} F z_{V_O}}{RT} \\frac{\\partial C_{V_O}}{\\partial x} \\frac{\\partial \\phi_f}{\\partial x} + \\frac{D_{V_O} F z_{V_O}}{RT} C_{V_O} \\frac{\\partial^2 \\phi_f}{\\partial x^2}\n",
    "                              \n",
    "\\frac{\\partial C_{V_{Cr}}}{\\partial t} = D_{V_{Cr}} \\frac{\\partial^2 C_{V_{Cr}}}{\\partial x^2} + \\frac{D_{V_{Cr}} F z_{V_{Cr}}}{RT} \\frac{\\partial C_{V_{Cr}}}{\\partial x} \\frac{\\partial \\phi_f}{\\partial x} + \\frac{D_{V_{Cr}} F z_{V_{Cr}}}{RT} C_{V_{Cr}} \\frac{\\partial^2 \\phi_f}{\\partial x^2}\n",
    "\n",
    "\\frac{\\partial C_{Cr_i}}{\\partial t} = D_{Cr_i} \\frac{\\partial^2 C_{Cr_i}}{\\partial x^2} + \\frac{D_{Cr_i} F z_{Cr_i}}{RT} \\frac{\\partial C_{Cr_i}}{\\partial x} \\frac{\\partial \\phi_f}{\\partial x} + \\frac{D_{Cr_i} F z_{Cr_i}}{RT} C_{Cr_i} \\frac{\\partial^2 \\phi_f}{\\partial x^2}\n",
    "\n",
    "\\frac{\\partial C_i}{\\partial t} = D_i \\frac{\\partial^2 C_i}{\\partial x^2} + \\frac{D_i F z_i}{RT} \\left( \\frac{\\partial C_i}{\\partial x} \\frac{\\partial \\phi}{\\partial x} + C_i \\frac{\\partial^2 \\phi}{\\partial x^2} \\right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb721753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the loss functions\n",
    "def loss(residual):\n",
    "    return torch.mean(residual**2)\n",
    "\n",
    "\n",
    "#Analytically Prescribed Potentials per Seyeux\n",
    "def compute_potentials(x, t):\n",
    "    \"\"\"Compute analytical potentials from Seyeux model\"\"\"\n",
    "    \n",
    "    # Dynamic interfacial potentials\n",
    "    phi_mf = phi_mf_0  # constant\n",
    "    phi_fs = phi_fs_0 + alpha * delta_V * torch.exp(-x / x_d)\n",
    "    phi_f = phi_f_i + delta_V * (1 - alpha * torch.exp(-x / x_d))\n",
    "    \n",
    "    return phi_mf, phi_fs, phi_f\n",
    "\n",
    "def compute_potential_derivatives(x, t):\n",
    "    \"\"\"Compute analytical derivatives of potentials\"\"\"\n",
    "    \n",
    "    # φ_f derivatives\n",
    "    phi_f_x = (delta_V * alpha / x_d) * torch.exp(-x / x_d)  # ∂φ_f/∂x\n",
    "    \n",
    "    # φ_fs derivatives  \n",
    "    phi_fs_x = -(alpha * delta_V / x_d) * torch.exp(-x / x_d)  # ∂φ_fs/∂x\n",
    "    \n",
    "    # φ_mf derivatives\n",
    "    phi_mf_x = torch.zeros_like(x)  # constant, so derivative = 0\n",
    "\n",
    "    phi_f_xx = -(delta_V * alpha/ x_d**2) * torch.exp(-x/x_d)\n",
    "\n",
    "    phi_fs_xx = (alpha * delta_V / x_d**2) * torch.exp(-x / x_d)  \n",
    "    \n",
    "    return phi_f_x, phi_fs_x, phi_mf_x, phi_f_xx, phi_fs_xx\n",
    "\n",
    "\n",
    "#Compute the Interior PDE's\n",
    "\n",
    "def interior_loss(x: torch.Tensor, t: torch.Tensor):\n",
    "    grads = compute_gradients(x, t)\n",
    "    phi_f_x, phi_fs_x, phi_mf_x, phi_f_xx, phi_fs_xx = compute_potential_derivatives(x,t)\n",
    "\n",
    "    # Calculate the PDE residuals for each species\n",
    "\n",
    "    ov_residual = grads.c_ov_t - (D_vo*grads.c_ov_xx + \n",
    "                                D_vo*F*z_ov*(1/(R*T))*grads.c_ov_x*phi_f_x + \n",
    "                                D_vo*grads.c_ov*z_ov*(F/(R*T))*phi_f_xx)\n",
    "\n",
    "    cv_residual = grads.c_cv_t - (D_MCr*grads.c_cv_xx + \n",
    "                                D_MCr*F*z_MCr*(1/(R*T))*grads.c_cv_x*phi_f_x + \n",
    "                                D_MCr*grads.c_cv*z_MCr*(F/(R*T))*phi_f_xx)\n",
    "\n",
    "    cir_residual = grads.c_cir_t - (D_ICr*grads.c_cir_xx + \n",
    "                                    D_ICr*F*z_ICr*(1/(R*T))*grads.c_cir_x*phi_f_x + \n",
    "                                    D_ICr*grads.c_cir*z_ICr*(F/(R*T))*phi_f_xx)\n",
    "\n",
    "    \n",
    "    interior = loss(ov_residual) + loss(cv_residual) + loss(cir_residual)\n",
    "\n",
    "    return interior, ov_residual, cv_residual, cir_residual\n",
    "\n",
    "\n",
    "def boundary_loss(x:torch.Tensor, t:torch.Tensor):\n",
    "\n",
    "    grads = compute_gradients(x,t)\n",
    "    phi_mf, phi_fs, phi_f = compute_potentials(x,t)\n",
    "    phi_f_x, phi_fs_x, phi_mf_x, phi_f_xx, phi_fs_xx = compute_potential_derivatives(x,t)\n",
    "\n",
    "    batch_size = x.shape[0]\n",
    "    half_batch = batch_size // 2\n",
    "    \n",
    "    # Split into metal/film and film/solution interface points\n",
    "    mf_indices = torch.arange(half_batch)\n",
    "    fs_indices = torch.arange(half_batch, batch_size)\n",
    "    \n",
    "    # Use interior points (middle of film) as reference\n",
    "    # Sample some interior points for reference\n",
    "    L_pred = L_net(t)\n",
    "    x_interior = 0.5 * L_pred  # Middle of film\n",
    "    \n",
    "    # Get interior concentrations as reference\n",
    "    interior_inputs = torch.cat([x_interior, t], dim=1)\n",
    "    c_ov_interior = ov_net(interior_inputs)\n",
    "    c_cv_interior = cv_net(interior_inputs) \n",
    "    c_cir_interior = cir_net(interior_inputs)\n",
    "    \n",
    "    # Dynamic potentials\n",
    "    phi_fs = phi_fs_0 + alpha * delta_V * torch.exp(-x[fs_indices] / x_d)\n",
    "\n",
    "    # Metal/film interface ratios - expand to match batch size\n",
    "    ratio_mf_ov_scalar = torch.exp(torch.tensor((delta_G1 + z_ov*F*phi_mf) / (R*T), device=device))\n",
    "    ratio_mf_cv_scalar = torch.exp(torch.tensor((delta_G2 + z_MCr*F*phi_mf) / (R*T), device=device))\n",
    "    ratio_mf_cir_scalar = torch.exp(torch.tensor((delta_G3 + z_ICr*F*phi_mf) / (R*T), device=device))\n",
    "\n",
    "    # Expand to match half_batch size\n",
    "    ratio_mf_ov = ratio_mf_ov_scalar.expand(half_batch, 1)\n",
    "    ratio_mf_cv = ratio_mf_cv_scalar.expand(half_batch, 1)\n",
    "    ratio_mf_cir = ratio_mf_cir_scalar.expand(half_batch, 1)\n",
    "\n",
    "    # Film/solution interface ratios  \n",
    "    ratio_fs_ov = torch.exp((delta_G8 + z_ov*F*phi_fs) / (R*T))     # Reaction 8\n",
    "    ratio_fs_cv = torch.exp((delta_G9 + z_MCr*F*phi_fs) / (R*T))    # Reaction 9\n",
    "    ratio_fs_cir = torch.exp((delta_G10 + z_ICr*F*phi_fs) / (R*T))  # Reaction 10\n",
    "\n",
    "    # Calculate residuals\n",
    "    mf_ov_residual = (grads.c_ov[mf_indices] / c_ov_interior[:half_batch]) - ratio_mf_ov\n",
    "    mf_cv_residual = (grads.c_cv[mf_indices] / c_cv_interior[:half_batch]) - ratio_mf_cv\n",
    "    mf_cir_residual = (grads.c_cir[mf_indices] / c_cir_interior[:half_batch]) - ratio_mf_cir\n",
    "    \n",
    "    fs_ov_residual = (grads.c_ov[fs_indices] / c_ov_interior[half_batch:]) - ratio_fs_ov\n",
    "    fs_cv_residual = (grads.c_cv[fs_indices] / c_cv_interior[half_batch:]) - ratio_fs_cv\n",
    "    fs_cir_residual = (grads.c_cir[fs_indices] / c_cir_interior[half_batch:]) - ratio_fs_cir\n",
    "    \n",
    "    # Calculate losses\n",
    "    mf_ov_loss = loss(mf_ov_residual)\n",
    "    mf_cv_loss = loss(mf_cv_residual)\n",
    "    mf_cir_loss = loss(mf_cir_residual)\n",
    "    \n",
    "    fs_ov_loss = loss(fs_ov_residual)\n",
    "    fs_cv_loss = loss(fs_cv_residual)\n",
    "    fs_cir_loss = loss(fs_cir_residual)\n",
    "    \n",
    "    mf_boundary_loss = mf_ov_loss + mf_cv_loss + mf_cir_loss\n",
    "    fs_boundary_loss = fs_ov_loss + fs_cv_loss + fs_cir_loss\n",
    "    boundary_loss = mf_boundary_loss + fs_boundary_loss\n",
    "    \n",
    "    residuals = {\n",
    "        \"mf_ov\": mf_ov_residual,\n",
    "        \"mf_cv\": mf_cv_residual,\n",
    "        \"mf_cir\": mf_cir_residual,\n",
    "        \"fs_ov\":fs_ov_residual,\n",
    "        \"fs_cv\": fs_cv_residual,\n",
    "        \"fs_cir\":fs_cir_residual\n",
    "    }\n",
    "\n",
    "    return boundary_loss, residuals\n",
    "    \n",
    "def compute_film_physics_loss(t):\n",
    "    \"\"\"\n",
    "    Compute film growth physics loss based on Seyeux flux formulation.\n",
    "    \n",
    "    Film growth: dx/dt = (Ω/N_V) * [J_VO + J_MCr + J_ICr]\n",
    "    \"\"\"\n",
    "    batch_size = t.shape[0]\n",
    "    \n",
    "    # Get film thickness and its time derivative\n",
    "    L_inputs = t\n",
    "    L_pred = L_net(L_inputs)\n",
    "    L_t = _grad(L_pred, t)\n",
    "    \n",
    "    # Sample points at film/solution interface (x = L) to compute fluxes\n",
    "    x_interface = L_pred  # x = L(t)\n",
    "    interface_inputs = torch.cat([x_interface, t], dim=1)\n",
    "    \n",
    "    # Get concentrations and gradients at interface\n",
    "    c_ov = ov_net(interface_inputs)\n",
    "    c_cv = cv_net(interface_inputs) \n",
    "    c_cir = cir_net(interface_inputs)\n",
    "    \n",
    "    c_ov_x = _grad(c_ov, x_interface)\n",
    "    c_cv_x = _grad(c_cv, x_interface)\n",
    "    c_cir_x = _grad(c_cir, x_interface)\n",
    "    \n",
    "    # Analytical potential derivatives at interface\n",
    "    phi_f_x = (delta_V * alpha / x_d) * torch.exp(-x_interface / x_d)\n",
    "    \n",
    "    # Calculate species fluxes using Nernst-Planck\n",
    "    # J_i = -D_i * (∂C_i/∂x + (z_i*F*C_i/RT) * ∂φ/∂x)\n",
    "    J_ov = -D_vo * (c_ov_x + (z_ov*F*c_ov/(R*T)) * phi_f_x)\n",
    "    J_cv = -D_MCr * (c_cv_x + (z_MCr*F*c_cv/(R*T)) * phi_f_x)\n",
    "    J_cir = -D_ICr * (c_cir_x + (z_ICr*F*c_cir/(R*T)) * phi_f_x)\n",
    "    \n",
    "    # Total flux contributing to film growth\n",
    "    J_total = J_ov + J_cv + J_cir\n",
    "    \n",
    "    # Expected film growth rate from flux\n",
    "    expected_growth_rate = (Omega / N_V) * J_total\n",
    "    \n",
    "    # Film physics residual\n",
    "    film_residual = L_t - expected_growth_rate\n",
    "    \n",
    "    # Loss\n",
    "    film_loss = loss(film_residual)\n",
    "    \n",
    "    return film_loss, film_residual\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8acfb73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the Total Loss and Intialize any training parameters\n",
    "\n",
    "def total_loss():\n",
    "    x_interior, t_interior = sample_interior_points()\n",
    "    x_boundary, t_boundary = sample_boundary_points()\n",
    "    t_film = sample_film_physics_points()\n",
    "\n",
    "    interior, ov_residual, cv_residual, cir_residual = interior_loss(x_interior,t_interior)\n",
    "    boundary,residuals = boundary_loss(x_boundary,t_boundary)\n",
    "    film_loss, film_residual = compute_film_physics_loss(t_film)\n",
    "\n",
    "    total_loss = interior + (1e-15)*boundary + film_loss \n",
    "\n",
    "    return total_loss, interior, (1e-15)*boundary,film_loss\n",
    "\n",
    "\n",
    "loss_history = {\n",
    "    'total': [], 'interior': [], 'boundary': [], 'film': []\n",
    "}\n",
    "\n",
    "lr = 1e-3\n",
    "max_steps = 30000\n",
    "print_freq = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05ab66b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a330d562a8104c52b75207f68c555fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Status:   0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:1.3435707092285156, interior:0.0035064537078142166, boundary:1.3395941257476807,film:0.00047014132724143565 at step:0\n",
      "Total:1.3395966291427612, interior:2.4897085495467763e-06, boundary:1.3395941257476807,film:5.061082930524208e-08 at step:100\n",
      "Total:1.339595913887024, interior:1.7382802752763382e-06, boundary:1.3395941257476807,film:2.890074668471243e-08 at step:200\n",
      "Total:1.3395953178405762, interior:1.1691121244439273e-06, boundary:1.3395941257476807,film:1.6739043928737374e-08 at step:300\n",
      "Total:1.339595079421997, interior:9.28295037283533e-07, boundary:1.3395941257476807,film:9.38841360209608e-09 at step:400\n",
      "Total:1.339594841003418, interior:7.25257223166409e-07, boundary:1.3395941257476807,film:5.863178387244261e-09 at step:500\n",
      "Total:1.3395949602127075, interior:6.023690275469562e-07, boundary:1.3395943641662598,film:4.591556912458827e-09 at step:600\n",
      "Total:1.339594841003418, interior:4.5435916717906366e-07, boundary:1.3395943641662598,film:3.667703918353027e-09 at step:700\n",
      "Total:1.3395947217941284, interior:3.6824440030613914e-07, boundary:1.3395943641662598,film:3.4219644895472356e-09 at step:800\n",
      "Total:1.3395946025848389, interior:2.934051792635728e-07, boundary:1.3395943641662598,film:3.4611378207927146e-09 at step:900\n",
      "Total:1.3395946025848389, interior:2.3841667484703066e-07, boundary:1.3395943641662598,film:3.4081568678345775e-09 at step:1000\n",
      "Total:1.3395946025848389, interior:1.8242224086861825e-07, boundary:1.3395943641662598,film:3.2278759665160806e-09 at step:1100\n",
      "Total:1.3395944833755493, interior:1.3819762045841344e-07, boundary:1.3395943641662598,film:3.3060825188613308e-09 at step:1200\n",
      "Total:1.3395944833755493, interior:1.0702675723450739e-07, boundary:1.3395943641662598,film:3.0335685075044694e-09 at step:1300\n",
      "Total:1.3395944833755493, interior:7.718684713609036e-08, boundary:1.3395943641662598,film:3.1458329274869357e-09 at step:1400\n",
      "Total:1.3395943641662598, interior:5.466995034453248e-08, boundary:1.3395943641662598,film:3.0791917904338106e-09 at step:1500\n",
      "Total:1.3395943641662598, interior:3.860090203033906e-08, boundary:1.3395943641662598,film:2.8622559877788945e-09 at step:1600\n",
      "Total:1.3395943641662598, interior:2.663720266582459e-08, boundary:1.3395943641662598,film:2.791996855933121e-09 at step:1700\n",
      "Total:1.3395943641662598, interior:1.7622562964447752e-08, boundary:1.3395943641662598,film:2.74463962668392e-09 at step:1800\n",
      "Total:1.3395943641662598, interior:1.1227674789893172e-08, boundary:1.3395943641662598,film:2.469026760820725e-09 at step:1900\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m loss_val, interior, boundary, film_loss = total_loss()\n\u001b[32m     11\u001b[39m loss_total = interior + boundary + film_loss\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mloss_val\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m optimizer.step()\n\u001b[32m     16\u001b[39m loss_history[\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m].append(loss_total.item())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/physicsOxy/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/physicsOxy/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/physicsOxy/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer=torch.optim.Adam([{'params': total_model_parameters}],lr=lr)\n",
    "for step in tqdm(range(max_steps),desc=\"Training Status\"):\n",
    "    cv_net.train()\n",
    "    ov_net.train()\n",
    "    cir_net.train()\n",
    "    L_net.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    loss_val, interior, boundary, film_loss = total_loss()\n",
    "    loss_total = interior + boundary + film_loss\n",
    "    loss_val.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "        \n",
    "    loss_history[\"total\"].append(loss_total.item())\n",
    "    loss_history['interior'].append(interior.item())\n",
    "    loss_history['boundary'].append(boundary.item())\n",
    "    loss_history['film'].append(film_loss.item())\n",
    "\n",
    "    if step % print_freq == 0:\n",
    "        tqdm.write(f\"Total:{loss_total}, interior:{interior}, boundary:{boundary},film:{film_loss} at step:{step}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physicsOxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
